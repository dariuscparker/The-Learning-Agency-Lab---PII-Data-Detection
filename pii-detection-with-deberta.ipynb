{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66653,"databundleVersionId":7500999,"sourceType":"competition"}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Notebook submission for The Learning Agency Lab - PII Data Detection\n\n<font size=\"4\"> This notebook is a submission for the Kaggle competition ‘The Learning Agency Lab - PII Data Detection.’ The goal is to identify personal identifiable information within a corpus of student essays. Detailed information regarding the competition may be found at the link below:\nhttps://www.kaggle.com/c/pii-detection-removal-from-educational-data\n","metadata":{}},{"cell_type":"markdown","source":"<font size=\"4\">To begin, import the required packages. Note the \"Weights and Biases\" package is used to log the project. Wandb is a great tool to track the results of data science projects. \n\n<font size=\"4\">https://wandb.ai/site","metadata":{}},{"cell_type":"code","source":"#Import packages\nimport torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\nfrom sklearn.metrics import classification_report, precision_recall_fscore_support\nfrom collections import Counter\nimport datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport pandas as pd\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport gc\nimport re\nimport random\nfrom itertools import chain\n\nimport wandb\n# Initialize wandb\nwandb.init(project=\"pii-detection\")\n\n#Set random seeds for reproducibility\ndef set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nseed_value = 42  \nset_seed(seed_value)\n\nimport time\n# Capture the start time\nstart_time = time.time()\nprint(\"Start Time: \", time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time)))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:18:32.277001Z","iopub.execute_input":"2024-08-07T23:18:32.277793Z","iopub.status.idle":"2024-08-07T23:40:48.453936Z","shell.execute_reply.started":"2024-08-07T23:18:32.277759Z","shell.execute_reply":"2024-08-07T23:40:48.452982Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-07 23:18:39.610248: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-07 23:18:39.610362: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-07 23:18:39.741724: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.5 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240807_234031-1kn475p3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/deeparker239/pii-detection/runs/1kn475p3' target=\"_blank\">dandy-puddle-58</a></strong> to <a href='https://wandb.ai/deeparker239/pii-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/deeparker239/pii-detection' target=\"_blank\">https://wandb.ai/deeparker239/pii-detection</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/deeparker239/pii-detection/runs/1kn475p3' target=\"_blank\">https://wandb.ai/deeparker239/pii-detection/runs/1kn475p3</a>"},"metadata":{}},{"name":"stdout","text":"Start Time:  2024-08-07 23:40:48\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Data\n<font size=\"4\">Load the training data from the provided JSON file and create a Hugging Face Dataset object. The data is split into training and evaluation sets.","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndataset = datasets.load_dataset('json', data_files='/kaggle/input/pii-detection-removal-from-educational-data/train.json')\n\n# Convert to DataFrame and preprocess\ndf = dataset['train'].to_pandas()\nall_labels = [label for sublist in df['labels'] for label in sublist]\nunique_labels = list(set(all_labels))\nid2label = {i: label for i, label in enumerate(unique_labels)}\nlabel2id = {label: i for i, label in enumerate(unique_labels)}\nall_labels = list(label2id.keys())  # Get all unique labels from mapping\nnum_labels = len(all_labels)  # Update the num_labels\n\n# Tokenizer and Model\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\nmodel = AutoModelForTokenClassification.from_pretrained(\"microsoft/deberta-v3-base\", num_labels=num_labels, id2label=id2label, label2id=label2id)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Split Dataset\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\ntrain_dataset = datasets.Dataset.from_pandas(train_df)\ntest_dataset = datasets.Dataset.from_pandas(test_df)\ndataset_dict = datasets.DatasetDict({'train': train_dataset, 'test': test_dataset})\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:40:48.455802Z","iopub.execute_input":"2024-08-07T23:40:48.456430Z","iopub.status.idle":"2024-08-07T23:41:03.779125Z","shell.execute_reply.started":"2024-08-07T23:40:48.456397Z","shell.execute_reply":"2024-08-07T23:41:03.778115Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d47ebd9291d4e1dbc01ab73f016d8b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c5ae437066148bc8b949684f9d8c6f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"203ab6a1640f45f98e2966ea58c6f585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"964715b85ce8400c987a86fc485e3ece"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd4f25f2b4b244048cb5606e9e39d6aa"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<font size=\"4\">We can explore the dataset object. ","metadata":{}},{"cell_type":"code","source":"print('Dataset length', len(dataset))\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:41:03.781240Z","iopub.execute_input":"2024-08-07T23:41:03.782071Z","iopub.status.idle":"2024-08-07T23:41:03.790069Z","shell.execute_reply.started":"2024-08-07T23:41:03.782043Z","shell.execute_reply":"2024-08-07T23:41:03.789053Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Dataset length 1\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['document', 'full_text', 'tokens', 'trailing_whitespace', 'labels'],\n        num_rows: 6807\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"<font size=\"4\">The dataset has four columns, 'document', 'tokens', 'labels', and 'trailing_whitespace'. Pandas can be used to visualize the dataset and get a better understanding of the structure. Note that pandas is used for visualization purposes only. The datasets library is needed to use with the Hugging Face model. Some may argue that it is not best practice to not include Pandas in final production code (possible slower performance). ","metadata":{}},{"cell_type":"code","source":"df = pd.read_json('/kaggle/input/pii-detection-removal-from-educational-data/train.json')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:41:03.792818Z","iopub.execute_input":"2024-08-07T23:41:03.793128Z","iopub.status.idle":"2024-08-07T23:41:05.348856Z","shell.execute_reply.started":"2024-08-07T23:41:03.793104Z","shell.execute_reply":"2024-08-07T23:41:05.347816Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   document                                          full_text  \\\n0         7  Design Thinking for innovation reflexion-Avril...   \n1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n4        56  Assignment:  Visualization Reflection  Submitt...   \n\n                                              tokens  \\\n0  [Design, Thinking, for, innovation, reflexion,...   \n1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n4  [Assignment, :,   , Visualization,  , Reflecti...   \n\n                                 trailing_whitespace  \\\n0  [True, True, True, True, False, False, True, F...   \n1  [True, False, False, True, True, False, False,...   \n2  [True, False, False, True, True, False, False,...   \n3  [True, True, True, False, False, True, False, ...   \n4  [False, False, False, False, False, False, Fal...   \n\n                                              labels  \n0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>document</th>\n      <th>full_text</th>\n      <th>tokens</th>\n      <th>trailing_whitespace</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>Design Thinking for innovation reflexion-Avril...</td>\n      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n      <td>[True, True, True, True, False, False, True, F...</td>\n      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n      <td>[True, False, False, True, True, False, False,...</td>\n      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n      <td>[True, False, False, True, True, False, False,...</td>\n      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n      <td>[True, True, True, False, False, True, False, ...</td>\n      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>56</td>\n      <td>Assignment:  Visualization Reflection  Submitt...</td>\n      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n      <td>[False, False, False, False, False, False, Fal...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<font size=\"4\">The pandas data frame produces a better visualization of the structure of the JSON file. Each row represents an essay written by a student. There are 6807 Rows in the data frame, each row representing a student essay. The column 'full text' contains the full essay. The 'Tokens' column contains the text separated by tokens. The trailing white space column is a list of placeholders indicating if a token contains a trailing white space. Finally, the labels column represents a label for each token. Each token is as  one of our desired categories of PII, or 'O' if the token does not belong to PII a category.\n    \n<font size=\"4\">We can view the first full essay as an example. A function 'format_text' is used to make the document more readable for humans.","metadata":{}},{"cell_type":"markdown","source":"\n\n","metadata":{}},{"cell_type":"code","source":"def format_text(text):\n    # Add paragraph breaks\n    formatted_text = text.replace('\\n\\n', '\\n\\n<p>\\n\\n')\n\n    # Add bullet points to list items\n    formatted_text = re.sub(r'•\\s', '\\n- ', formatted_text)\n\n    # Handle remaining single newlines\n    formatted_text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', formatted_text)\n    \n    # Remove leading and trailing spaces\n    formatted_text = re.sub(r'\\s+\\n', '\\n', formatted_text)\n    formatted_text = re.sub(r'\\n\\s+', '\\n', formatted_text)\n\n    return formatted_text\n\n# Example usage\nraw_text = df['full_text'][0]\n\nprint(format_text(raw_text))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:41:05.350526Z","iopub.execute_input":"2024-08-07T23:41:05.351153Z","iopub.status.idle":"2024-08-07T23:41:05.361410Z","shell.execute_reply.started":"2024-08-07T23:41:05.351112Z","shell.execute_reply":"2024-08-07T23:41:05.360532Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Design Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n<p>\nChallenge & selection\n<p>\nThe tool I use to help all stakeholders finding their way through the complexity of a project is the  mind map.\n<p>\nWhat exactly is a mind map? According to the definition of Buzan T. and Buzan B. (1999, Dessine-moi  l'intelligence. Paris: Les Éditions d'Organisation.), the mind map (or heuristic diagram) is a graphic  representation technique that follows the natural functioning of the mind and allows the brain's  potential to be released. Cf Annex1\n<p>\nThis tool has many advantages:\n<p>\n-  It is accessible to all and does not require significant material investment and can be done  quickly\n<p>\n-  It is scalable\n<p>\n-  It allows categorization and linking of information\n<p>\n-  It can be applied to any type of situation: notetaking, problem solving, analysis, creation of  new ideas\n<p>\n-  It is suitable for all people and is easy to learn\n<p>\n-  It is fun and encourages exchanges\n<p>\n-  It makes visible the dimension of projects, opportunities, interconnections\n<p>\n-  It synthesizes\n<p>\n-  It makes the project understandable\n<p>\n-  It allows you to explore ideas\n<p>\nThe creation of a mind map starts with an idea/problem located at its center. This starting point  generates ideas/work areas, incremented around this center in a radial structure, which in turn is  completed with as many branches as new ideas.\n<p>\nThis tool enables creativity and logic to be mobilized, it is a map of the thoughts.\n<p>\nCreativity is enhanced because participants feel comfortable with the method.\n<p>\nApplication & Insight\n<p>\nI start the process of the mind map creation with the stakeholders standing around a large board  (white or paper board). In the center of the board, I write and highlight the topic to design.\n<p>\nThrough a series of questions, I guide the stakeholders in modelling the mind map. I adapt the series  of questions according to the topic to be addressed. In the type of questions, we can use: who, what,  when, where, why, how, how much.\n<p>\nThe use of the “why” is very interesting to understand the origin. By this way, the interviewed person  frees itself from paradigms and thus dares to propose new ideas / ways of functioning. I plan two  hours for a workshop.\n<p>\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n<p>\nAfter modelling the mind map on paper, I propose to the participants a digital visualization of their  work with the addition of color codes, images and interconnections. This second workshop also lasts  two hours and allows the mind map to evolve. Once familiarized with it, the stakeholders discover  the power of the tool. Then, the second workshop brings out even more ideas and constructive  exchanges between the stakeholders. Around this new mind map, they have learned to work  together and want to make visible the untold ideas.\n<p>\nI now present all the projects I manage in this type of format in order to ease rapid understanding for  decision-makers. These presentations are the core of my business models. The decision-makers are  thus able to identify the opportunities of the projects and can take quick decisions to validate them.  They find answers to their questions thank to a schematic representation.\n<p>\nApproach\n<p>\nWhat I find amazing with the facilitation of this type of workshop is the participants commitment for  the project. This tool helps to give meaning. The participants appropriate the story and want to keep  writing it. Then, they easily become actors or sponsors of the project. A trust relationship is built,  thus facilitating the implementation of related actions.\n<p>\nDesign Thinking for innovation reflexion-Avril 2021-Nathalie Sylla\n<p>\nAnnex 1: Mind Map Shared facilities project\n<p>\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<font size=\"4\"> We can also get the distribution of the unique labels. ","metadata":{}},{"cell_type":"code","source":"# Count the frequency of each label in the 'train' dataset\nlabel_freq = Counter(chain(*train_dataset['labels']))\n\n# Display the frequency of each label\nfor label, freq in label_freq.items():\n    print(f\"Label: {label}, Frequency: {freq}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:41:05.362556Z","iopub.execute_input":"2024-08-07T23:41:05.362891Z","iopub.status.idle":"2024-08-07T23:41:10.905172Z","shell.execute_reply.started":"2024-08-07T23:41:05.362860Z","shell.execute_reply":"2024-08-07T23:41:10.904251Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Label: O, Frequency: 3984659\nLabel: B-NAME_STUDENT, Frequency: 1102\nLabel: I-NAME_STUDENT, Frequency: 852\nLabel: B-ID_NUM, Frequency: 68\nLabel: B-URL_PERSONAL, Frequency: 82\nLabel: B-EMAIL, Frequency: 36\nLabel: B-USERNAME, Frequency: 6\nLabel: B-PHONE_NUM, Frequency: 4\nLabel: I-PHONE_NUM, Frequency: 12\nLabel: I-URL_PERSONAL, Frequency: 1\nLabel: I-ID_NUM, Frequency: 1\nLabel: B-STREET_ADDRESS, Frequency: 1\nLabel: I-STREET_ADDRESS, Frequency: 10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<font size=\"4\">The data set is heavily distributed with tokens that do not belong to a PII category (ie 'O' labels). We will use a focal loss and class weights with our model to help with this class imbalance. This will help ensure our model does not simply predict all 'O's' given the large distribution of those labels.","metadata":{}},{"cell_type":"markdown","source":"# Tokenization and Alignment of Labels","metadata":{}},{"cell_type":"markdown","source":"<font size=\"4\">Explanations of the unique labels in the data set are below. These are the desired PII categories we seek to identify in the student essays. Note the tokens are split using a 'piece wise' tokenizer format. ","metadata":{}},{"cell_type":"markdown","source":"# **Explanation of Labels:**\n\n<font size=\"4\">\n\n- **B-EMAIL**: Beginning of an email address.\n- **B-ID_NUM**: Beginning of an identification number.\n- **B-NAME_STUDENT**: Beginning of a student's name.\n- **B-PHONE_NUM**: Beginning of a phone number.\n- **B-STREET_ADDRESS**: Beginning of a street address.\n- **B-URL_PERSONAL**: Beginning of a personal URL.\n- **B-USERNAME**: Beginning of a username.\n- **I-ID_NUM**: Inside an identification number.\n- **I-NAME_STUDENT**: Inside a student's name.\n- **I-PHONE_NUM**: Inside a phone number.\n- **I-STREET_ADDRESS**: Inside a street address.\n- **I-URL_PERSONAL**: Inside a personal URL.\n- **O**: Outside of any named entity.\n\n**Piecewise Tokenization:**\n\nThe DeBERTa model uses a 'piecewise' tokenizer. This type of tokenizer breaks down text into smaller subword units, which is useful for handling rare words and morphological variations. It ensures that even if a word is not in the vocabulary, the tokenizer can still represent it using smaller known subword units.\n\n**Tokenization Process:**\n\n- **Token Splitting**: The text is split into tokens based on whitespace and punctuation.\n- **Subword Tokenization**: Each token is further split into subwords. For example, the word \"unhappiness\" might be split into \"un\", \"happi\", and \"ness\".\n- **Label Alignment**: Labels are aligned with the subword tokens. If a token is split into multiple subwords, the label for the original token is assigned to the first subword, and a special label (typically -100) is assigned to the subsequent subwords.\n\nHere's an example of how a token and its label might be split and aligned:\n\nOriginal token: \"unhappiness\" (Label: B-EMOTION)\nSubword tokens: [\"un\", \"happi\", \"ness\"]\nAligned labels: [B-EMOTION, -100, -100]\n\nThe alignment ensures that the model learns to identify entities correctly even when tokens are split into subwords.\n    \n</font>\n","metadata":{}},{"cell_type":"markdown","source":"<font size=\"4\"> A function to tokenize the input data and align the labels with the tokenized inputs s also defined. his function handles the trailing whitespace correctly. The map function, which is included in the datasets library, is used to map the function to all of the documents in the data set. This will create the tokenized dataset required for the Hugging Face Deberta model.\n","metadata":{}},{"cell_type":"code","source":"#Define function to tokenize and align labels\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        is_split_into_words=True,\n        truncation=True,\n        padding='max_length',\n        max_length=1024,\n        return_offsets_mapping=True\n    )\n\n    batch_original_tokens = []\n    batch_tokenized_tokens = []\n    batch_label_ids = []\n    batch_input_ids = []\n    batch_attention_masks = []\n    batch_token_type_ids = []\n\n    for i, label in enumerate(examples[\"labels\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        original_tokens = examples[\"tokens\"][i]\n        tokenized_tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"][i])\n\n        previous_word_idx = None\n        label_ids = []\n        original_token_list = []\n        tokenized_token_list = []\n        input_id_list = []\n        attention_mask_list = []\n        token_type_id_list = []\n\n        for j, word_idx in enumerate(word_ids):\n            if word_idx is None:\n                label_ids.append(-100)\n                current_original_token = ''  # Special token\n            elif word_idx == previous_word_idx:\n                label_ids.append(-100)\n                current_original_token = ''  # Subword token\n            else:\n                label_ids.append(label2id[label[word_idx]])\n                current_original_token = original_tokens[word_idx]\n\n            original_token_list.append(current_original_token)\n            tokenized_token_list.append(tokenized_tokens[j])\n            input_id_list.append(tokenized_inputs[\"input_ids\"][i][j])\n            attention_mask_list.append(tokenized_inputs[\"attention_mask\"][i][j])\n            if \"token_type_ids\" in tokenized_inputs:\n                token_type_id_list.append(tokenized_inputs[\"token_type_ids\"][i][j])\n            else:\n                token_type_id_list.append(0)\n            previous_word_idx = word_idx  # Update for the next iteration\n\n        batch_original_tokens.append(original_token_list)\n        batch_tokenized_tokens.append(tokenized_token_list)\n        batch_label_ids.append(label_ids)\n        batch_input_ids.append(input_id_list)\n        batch_attention_masks.append(attention_mask_list)\n        batch_token_type_ids.append(token_type_id_list)\n\n    # Include BERT-required columns\n    return {\n        \"original_tokens\": batch_original_tokens,\n        \"tokenized_tokens\": batch_tokenized_tokens,\n        \"labels\": batch_label_ids,\n        \"input_ids\": batch_input_ids,  \n        \"attention_mask\": batch_attention_masks,\n        \"token_type_ids\": batch_token_type_ids  \n    }\n\n# Tokenize\ntokenized_datasets = dataset_dict.map(tokenize_and_align_labels, batched=True)\n\ngc.collect()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:41:10.907354Z","iopub.execute_input":"2024-08-07T23:41:10.907634Z","iopub.status.idle":"2024-08-07T23:42:09.888354Z","shell.execute_reply.started":"2024-08-07T23:41:10.907611Z","shell.execute_reply":"2024-08-07T23:42:09.887415Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5445 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8edceb88f4714451bdefa0e8d6125b6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a71a8d025240d48cabb13090120ecd"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"1389"},"metadata":{}}]},{"cell_type":"markdown","source":"<font size=\"4\">It is important to ensure the tokenizer works correctly. The function below displays a comparison of the original tokens to the processed tokens.","metadata":{}},{"cell_type":"code","source":"import datasets\n\n# Function to print the first few elements of each relevant column\ndef print_comparison(dataset, num_elements=20):\n    first_document = dataset[0]\n    original_tokens = first_document['original_tokens'][:num_elements]\n    tokenized_tokens = first_document['tokenized_tokens'][:num_elements]\n    labels = first_document['labels'][:num_elements]\n    input_ids = first_document['input_ids'][:num_elements]\n    attention_mask = first_document['attention_mask'][:num_elements]\n    token_type_ids = first_document['token_type_ids'][:num_elements]\n\n    # Print the columns in a readable format\n    for i in range(num_elements):\n        print(f\"Original Token: {original_tokens[i]:<15} | \"\n              f\"Tokenized Token: {tokenized_tokens[i]:<20} | \"\n              f\"Label: {labels[i]:<5} | \"\n              f\"Input ID: {input_ids[i]:<10} | \"\n              f\"Attention Mask: {attention_mask[i]:<5} | \"\n              f\"Token Type ID: {token_type_ids[i]}\")\n\n# Example usage with the train dataset\nprint(\"Comparison of first 20 elements for the first document in the train dataset:\")\nprint_comparison(tokenized_datasets['train'], num_elements=20)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:42:09.889665Z","iopub.execute_input":"2024-08-07T23:42:09.890028Z","iopub.status.idle":"2024-08-07T23:42:09.909940Z","shell.execute_reply.started":"2024-08-07T23:42:09.889995Z","shell.execute_reply":"2024-08-07T23:42:09.909023Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Comparison of first 20 elements for the first document in the train dataset:\nOriginal Token:                 | Tokenized Token: [CLS]                | Label: -100  | Input ID: 1          | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Visualization   | Tokenized Token: ▁Visualization       | Label: 1     | Input ID: 51146      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: tool            | Tokenized Token: ▁tool                | Label: 1     | Input ID: 1637       | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: to              | Tokenized Token: ▁to                  | Label: 1     | Input ID: 264        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: control         | Tokenized Token: ▁control             | Label: 1     | Input ID: 719        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Humidity        | Tokenized Token: ▁Humidity            | Label: 1     | Input ID: 79916      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: &               | Tokenized Token: ▁&                   | Label: 1     | Input ID: 429        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Temp            | Tokenized Token: ▁Temp                | Label: 1     | Input ID: 26872      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: in              | Tokenized Token: ▁in                  | Label: 1     | Input ID: 267        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Spinning        | Tokenized Token: ▁Spinning            | Label: 1     | Input ID: 53791      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Plant           | Tokenized Token: ▁Plant               | Label: 1     | Input ID: 6075       | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Challenge       | Tokenized Token: ▁Challenge           | Label: 1     | Input ID: 6738       | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: &               | Tokenized Token: ▁&                   | Label: 1     | Input ID: 429        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Selection       | Tokenized Token: ▁Selection           | Label: 1     | Input ID: 14700      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: I               | Tokenized Token: ▁I                   | Label: 1     | Input ID: 273        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: am              | Tokenized Token: ▁am                  | Label: 1     | Input ID: 481        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Electronics     | Tokenized Token: ▁Electronics         | Label: 1     | Input ID: 12043      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: Engineer        | Tokenized Token: ▁Engineer            | Label: 1     | Input ID: 11496      | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: &               | Tokenized Token: ▁&                   | Label: 1     | Input ID: 429        | Attention Mask: 1     | Token Type ID: 0\nOriginal Token: working         | Tokenized Token: ▁working             | Label: 1     | Input ID: 560        | Attention Mask: 1     | Token Type ID: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<font size=\"4\">The tokenizer appears to have processed the original tokens correctly. We can remove the unnecessary column from the tokenized data set and only keep the columns required for training.","metadata":{}},{"cell_type":"code","source":"# List of columns to keep\ncolumns_to_keep = ['labels', 'input_ids', 'attention_mask', 'token_type_ids']\n\n# Function to remove unnecessary columns\ndef remove_unnecessary_columns(dataset, columns_to_keep):\n    return dataset.remove_columns([column for column in dataset.column_names if column not in columns_to_keep])\n\n# Apply the function to both train and test datasets\ntokenized_datasets['train'] = remove_unnecessary_columns(tokenized_datasets['train'], columns_to_keep)\ntokenized_datasets['test'] = remove_unnecessary_columns(tokenized_datasets['test'], columns_to_keep)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:42:09.911004Z","iopub.execute_input":"2024-08-07T23:42:09.911262Z","iopub.status.idle":"2024-08-07T23:42:09.927345Z","shell.execute_reply.started":"2024-08-07T23:42:09.911238Z","shell.execute_reply":"2024-08-07T23:42:09.926364Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Deberta Model Training\n<font size=\"4\">Recall the data set is imbalanced, with the vast majority of labels belonging to a non-PII category 'O.' Class weights with a weighted loss function will be used to help with this imbalance. This means the model will put more focus on the minority classes and will put less weight on the majority classes when training. Also, a custom compute metrics function with a classification report is defined for evaluation.","metadata":{}},{"cell_type":"code","source":"# Calculate class weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(all_labels), y=all_labels)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:42:09.930838Z","iopub.execute_input":"2024-08-07T23:42:09.931145Z","iopub.status.idle":"2024-08-07T23:42:09.941934Z","shell.execute_reply.started":"2024-08-07T23:42:09.931122Z","shell.execute_reply":"2024-08-07T23:42:09.940791Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Define data collator\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\n# Define Focal Loss\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, alpha=None):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        if isinstance(alpha, (float, int)):\n            self.alpha = torch.Tensor([alpha, 1 - alpha])\n        if isinstance(alpha, list):\n            self.alpha = torch.Tensor(alpha)\n\n    def forward(self, inputs, targets):\n        BCE_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n        pt = torch.exp(-BCE_loss)\n        F_loss = ((1 - pt) ** self.gamma) * BCE_loss\n        return F_loss.mean()\n\n# Define data collator\ndata_collator = DataCollatorForTokenClassification(tokenizer)\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    true_labels = [[id2label[label] for label in doc if label != -100] for doc in labels]\n    true_predictions = [\n        [id2label[pred] for pred, label in zip(doc, labels[i]) if label != -100]\n        for i, doc in enumerate(predictions)\n    ]\n\n    # Flatten the lists\n    true_labels_flat = [item for sublist in true_labels for item in sublist]\n    true_predictions_flat = [item for sublist in true_predictions for item in sublist]\n\n    # Calculate metrics\n    results = precision_recall_fscore_support(true_labels_flat, true_predictions_flat, average='weighted')\n    \n    # Compute classification report\n    class_report = classification_report(\n        true_labels_flat, true_predictions_flat, labels=all_labels, zero_division=0  # Explicitly set labels and handle zero division\n    )\n\n    print(\"Classification Report:\\n\", class_report)\n    return {\n        \"precision\": results[0],\n        \"recall\": results[1],\n        \"f1\": results[2],\n        \"accuracy\": (results[2] * results[1])\n    }\n\n# Custom Trainer with custom loss function\nclass CustomTrainer(Trainer):\n    def __init__(self, loss_fn, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.loss_fn = loss_fn\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n        \n        return (loss, outputs) if return_outputs else loss\n\n# Choose the loss function (WeightedLoss or FocalLoss)\nloss_fn = FocalLoss(gamma=2, alpha=class_weights)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    report_to='none'\n)\n\n# Trainer\ntrainer = CustomTrainer(\n    loss_fn=loss_fn,\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets['train'],\n    eval_dataset=tokenized_datasets['test'],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:42:09.943154Z","iopub.execute_input":"2024-08-07T23:42:09.943697Z","iopub.status.idle":"2024-08-07T23:42:09.997844Z","shell.execute_reply.started":"2024-08-07T23:42:09.943673Z","shell.execute_reply":"2024-08-07T23:42:09.996825Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer.train()\n\n# Evaluate the model\neval_results = trainer.evaluate()\nprint(eval_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-07T23:42:09.998949Z","iopub.execute_input":"2024-08-07T23:42:09.999216Z","iopub.status.idle":"2024-08-08T01:33:27.052639Z","shell.execute_reply.started":"2024-08-07T23:42:09.999193Z","shell.execute_reply":"2024-08-08T01:33:27.051617Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3405' max='3405' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3405/3405 1:48:58, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.003100</td>\n      <td>0.000119</td>\n      <td>0.999875</td>\n      <td>0.999891</td>\n      <td>0.999873</td>\n      <td>0.999764</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000200</td>\n      <td>0.000099</td>\n      <td>0.999865</td>\n      <td>0.999876</td>\n      <td>0.999865</td>\n      <td>0.999741</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000100</td>\n      <td>0.000092</td>\n      <td>0.999897</td>\n      <td>0.999901</td>\n      <td>0.999897</td>\n      <td>0.999798</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000000</td>\n      <td>0.000085</td>\n      <td>0.999908</td>\n      <td>0.999917</td>\n      <td>0.999912</td>\n      <td>0.999828</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>0.000079</td>\n      <td>0.999910</td>\n      <td>0.999911</td>\n      <td>0.999907</td>\n      <td>0.999818</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n                   precision    recall  f1-score   support\n\n        I-ID_NUM       0.00      0.00      0.00         0\n               O       1.00      1.00      1.00    887890\n      B-USERNAME       0.00      0.00      0.00         0\n  I-NAME_STUDENT       0.95      0.97      0.96       234\n  I-URL_PERSONAL       0.00      0.00      0.00         0\nI-STREET_ADDRESS       0.00      0.00      0.00         9\n     I-PHONE_NUM       0.00      0.00      0.00         3\n  B-URL_PERSONAL       1.00      0.15      0.26        27\n         B-EMAIL       0.75      1.00      0.86         3\n        B-ID_NUM       0.69      0.90      0.78        10\n  B-NAME_STUDENT       0.93      0.92      0.93       253\n     B-PHONE_NUM       0.00      0.00      0.00         2\nB-STREET_ADDRESS       0.00      0.00      0.00         1\n\n       micro avg       1.00      1.00      1.00    888432\n       macro avg       0.41      0.38      0.37    888432\n    weighted avg       1.00      1.00      1.00    888432\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n                   precision    recall  f1-score   support\n\n        I-ID_NUM       0.00      0.00      0.00         0\n               O       1.00      1.00      1.00    887890\n      B-USERNAME       0.00      0.00      0.00         0\n  I-NAME_STUDENT       0.96      0.94      0.95       234\n  I-URL_PERSONAL       0.00      0.00      0.00         0\nI-STREET_ADDRESS       0.00      0.00      0.00         9\n     I-PHONE_NUM       0.00      0.00      0.00         3\n  B-URL_PERSONAL       1.00      0.33      0.50        27\n         B-EMAIL       0.75      1.00      0.86         3\n        B-ID_NUM       0.69      0.90      0.78        10\n  B-NAME_STUDENT       0.86      0.95      0.90       253\n     B-PHONE_NUM       0.00      0.00      0.00         2\nB-STREET_ADDRESS       0.00      0.00      0.00         1\n\n       micro avg       1.00      1.00      1.00    888432\n       macro avg       0.40      0.39      0.38    888432\n    weighted avg       1.00      1.00      1.00    888432\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n                   precision    recall  f1-score   support\n\n        I-ID_NUM       0.00      0.00      0.00         0\n               O       1.00      1.00      1.00    887890\n      B-USERNAME       0.00      0.00      0.00         0\n  I-NAME_STUDENT       0.96      0.98      0.97       234\n  I-URL_PERSONAL       0.00      0.00      0.00         0\nI-STREET_ADDRESS       0.00      0.00      0.00         9\n     I-PHONE_NUM       0.00      0.00      0.00         3\n  B-URL_PERSONAL       0.64      1.00      0.78        27\n         B-EMAIL       0.75      1.00      0.86         3\n        B-ID_NUM       0.53      0.90      0.67        10\n  B-NAME_STUDENT       0.89      0.96      0.92       253\n     B-PHONE_NUM       0.00      0.00      0.00         2\nB-STREET_ADDRESS       0.00      0.00      0.00         1\n\n       micro avg       1.00      1.00      1.00    888432\n       macro avg       0.37      0.45      0.40    888432\n    weighted avg       1.00      1.00      1.00    888432\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n                   precision    recall  f1-score   support\n\n        I-ID_NUM       0.00      0.00      0.00         0\n               O       1.00      1.00      1.00    887890\n      B-USERNAME       0.00      0.00      0.00         0\n  I-NAME_STUDENT       0.95      0.99      0.97       234\n  I-URL_PERSONAL       0.00      0.00      0.00         0\nI-STREET_ADDRESS       0.00      0.00      0.00         9\n     I-PHONE_NUM       0.00      0.00      0.00         3\n  B-URL_PERSONAL       0.87      0.96      0.91        27\n         B-EMAIL       0.75      1.00      0.86         3\n        B-ID_NUM       0.64      0.90      0.75        10\n  B-NAME_STUDENT       0.89      0.96      0.93       253\n     B-PHONE_NUM       0.00      0.00      0.00         2\nB-STREET_ADDRESS       0.00      0.00      0.00         1\n\n       micro avg       1.00      1.00      1.00    888432\n       macro avg       0.39      0.45      0.42    888432\n    weighted avg       1.00      1.00      1.00    888432\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n                   precision    recall  f1-score   support\n\n        I-ID_NUM       0.00      0.00      0.00         0\n               O       1.00      1.00      1.00    887890\n      B-USERNAME       0.00      0.00      0.00         0\n  I-NAME_STUDENT       0.97      0.97      0.97       234\n  I-URL_PERSONAL       0.00      0.00      0.00         0\nI-STREET_ADDRESS       1.00      0.22      0.36         9\n     I-PHONE_NUM       0.00      0.00      0.00         3\n  B-URL_PERSONAL       0.86      0.93      0.89        27\n         B-EMAIL       0.75      1.00      0.86         3\n        B-ID_NUM       0.75      0.90      0.82        10\n  B-NAME_STUDENT       0.88      0.96      0.92       253\n     B-PHONE_NUM       0.00      0.00      0.00         2\nB-STREET_ADDRESS       0.00      0.00      0.00         1\n\n       micro avg       1.00      1.00      1.00    888432\n       macro avg       0.48      0.46      0.45    888432\n    weighted avg       1.00      1.00      1.00    888432\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Classification Report:\n                   precision    recall  f1-score   support\n\n        I-ID_NUM       0.00      0.00      0.00         0\n               O       1.00      1.00      1.00    887890\n      B-USERNAME       0.00      0.00      0.00         0\n  I-NAME_STUDENT       0.97      0.97      0.97       234\n  I-URL_PERSONAL       0.00      0.00      0.00         0\nI-STREET_ADDRESS       1.00      0.22      0.36         9\n     I-PHONE_NUM       0.00      0.00      0.00         3\n  B-URL_PERSONAL       0.86      0.93      0.89        27\n         B-EMAIL       0.75      1.00      0.86         3\n        B-ID_NUM       0.75      0.90      0.82        10\n  B-NAME_STUDENT       0.88      0.96      0.92       253\n     B-PHONE_NUM       0.00      0.00      0.00         2\nB-STREET_ADDRESS       0.00      0.00      0.00         1\n\n       micro avg       1.00      1.00      1.00    888432\n       macro avg       0.48      0.46      0.45    888432\n    weighted avg       1.00      1.00      1.00    888432\n\n{'eval_loss': 7.874904986238107e-05, 'eval_precision': 0.999909653303145, 'eval_recall': 0.9999110792947575, 'eval_f1': 0.9999072289289255, 'eval_accuracy': 0.999818316472952, 'eval_runtime': 135.0701, 'eval_samples_per_second': 10.084, 'eval_steps_per_second': 2.525, 'epoch': 5.0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Results\n<font size=\"4\"> The model achieved extremely high precision, recall, and F1 scores, all near or above 0.9999. This indicates the model performs exceptionally well in classifying the majority class 'O', however, this can be misleading due to the class imbalance. Some minority classes have a precision and recall of 0.00 due to insufficient samples. The number of samples in the evaluation set can be seen in the 'support' column in the classification report.\n    \n<font size=\"4\">A focal loss was used to help with the imbalance data set, however additional steps could be taken to help with this. Generating synthetic data with data augmentation could help, however this is CPU intensive and time consuming. For example, an attempt was made to generate 100 synthetic augmented examples for each of the underrepresented pii categories; the processing time for just 100 examples per category was over 90 minutes. It would be unfeasible to attempt a CPU augmentation for a data set of this size.\n    ","metadata":{}},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"# Load test dataset\ntest_dataset = datasets.load_dataset('json', data_files='/kaggle/input/pii-detection-removal-from-educational-data/test.json')['train']\n\ndef tokenize_test_set(examples):\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        is_split_into_words=True,\n        truncation=True,\n        padding='max_length',\n        max_length=1536,\n        return_offsets_mapping=True\n    )\n\n    batch_original_tokens = []\n    batch_tokenized_tokens = []\n    batch_input_ids = []\n    batch_attention_masks = []\n    batch_token_type_ids = []\n    batch_offset_mappings = []  # New line to store offset mappings\n\n    for i in range(len(examples[\"tokens\"])):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        original_tokens = examples[\"tokens\"][i]\n        tokenized_tokens = tokenizer.convert_ids_to_tokens(tokenized_inputs[\"input_ids\"][i])\n\n        original_token_list = []\n        tokenized_token_list = []\n        input_id_list = []\n        attention_mask_list = []\n        token_type_id_list = []\n\n        for j, word_idx in enumerate(word_ids):\n            current_original_token = '' if word_idx is None else original_tokens[word_idx]\n\n            original_token_list.append(current_original_token)\n            tokenized_token_list.append(tokenized_tokens[j])\n            input_id_list.append(tokenized_inputs[\"input_ids\"][i][j])\n            attention_mask_list.append(tokenized_inputs[\"attention_mask\"][i][j])\n            if \"token_type_ids\" in tokenized_inputs:\n                token_type_id_list.append(tokenized_inputs[\"token_type_ids\"][i][j])\n            else:\n                token_type_id_list.append(0)\n\n        batch_original_tokens.append(original_token_list)\n        batch_tokenized_tokens.append(tokenized_token_list)\n        batch_input_ids.append(input_id_list)\n        batch_attention_masks.append(attention_mask_list)\n        batch_token_type_ids.append(token_type_id_list)\n        # Append offset_mapping for the current sample\n        batch_offset_mappings.append(tokenized_inputs['offset_mapping'][i])\n\n    return {\n        \"original_tokens\": batch_original_tokens,\n        \"tokenized_tokens\": batch_tokenized_tokens,\n        \"input_ids\": batch_input_ids,\n        \"attention_mask\": batch_attention_masks,\n        \"token_type_ids\": batch_token_type_ids,\n        \"offset_mapping\": batch_offset_mappings,\n    }\n\ntest_dataset = test_dataset.map(tokenize_test_set, batched=True)\n\n# List of columns to keep\ncolumns_to_keep = ['document', 'input_ids', 'attention_mask', 'token_type_ids']\ntest_dataset = test_dataset.remove_columns([col for col in test_dataset.column_names if col not in columns_to_keep])\n\n# Define the confidence threshold\nconfidence_threshold = 0.95\n\n# Predict on test dataset\ntest_predictions = trainer.predict(test_dataset)\npred_probs = test_predictions.predictions\npreds = np.argmax(pred_probs, axis=2)\nmax_probs = np.max(pred_probs, axis=2)\n\n# Create submission file\nsubmission = []\n\nfor i, doc in enumerate(pred_probs):\n    word_ids = test_dataset[i]['input_ids']\n    for j, word_id in enumerate(word_ids):\n        if word_id != tokenizer.pad_token_id:\n            row_id = len(submission)\n            document_id = test_dataset[i]['document']\n            token_id = j\n            pred_label = id2label[preds[i][j]]\n            if pred_label != 'O' and max_probs[i][j] >= confidence_threshold:  # Exclude outside labels and apply threshold\n                submission.append([row_id, document_id, token_id, pred_label])\n\nsubmission_df = pd.DataFrame(submission, columns=[\"row_id\", \"document\", \"token\", \"label\"])\n\n# Save to CSV\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission file created successfully!\")","metadata":{"execution":{"iopub.status.busy":"2024-08-08T01:33:27.054072Z","iopub.execute_input":"2024-08-08T01:33:27.054364Z","iopub.status.idle":"2024-08-08T01:33:50.806473Z","shell.execute_reply.started":"2024-08-08T01:33:27.054338Z","shell.execute_reply":"2024-08-08T01:33:50.805540Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1ed1a1bd234c46bf078c6a56f4b50a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9eabefe2314e40e7bf6aa852528c811d"}},"metadata":{}},{"name":"stdout","text":"Submission file created successfully!\n","output_type":"stream"}]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2024-08-08T01:33:50.807769Z","iopub.execute_input":"2024-08-08T01:33:50.808031Z","iopub.status.idle":"2024-08-08T01:33:50.822361Z","shell.execute_reply.started":"2024-08-08T01:33:50.808007Z","shell.execute_reply":"2024-08-08T01:33:50.821385Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"    row_id  document  token           label\n0        0         7     11  B-NAME_STUDENT\n1        1         7     12  I-NAME_STUDENT\n2        2         7     13  I-NAME_STUDENT\n3        3         7    460  B-NAME_STUDENT\n4        4         7    461  I-NAME_STUDENT\n5        5         7    462  I-NAME_STUDENT\n6        6         7    706  B-NAME_STUDENT\n7        7         7    707  I-NAME_STUDENT\n8        8         7    708  I-NAME_STUDENT\n9        9        10      1  B-NAME_STUDENT\n10      10        10      2  I-NAME_STUDENT\n11      11        10    433  B-NAME_STUDENT\n12      12        10    434  I-NAME_STUDENT\n13      13        16      4  B-NAME_STUDENT\n14      14        16      5  I-NAME_STUDENT\n15      15        16      6  I-NAME_STUDENT\n16      16        20      5  B-NAME_STUDENT\n17      17        20      6  I-NAME_STUDENT\n18      18        20      7  I-NAME_STUDENT\n19      19        20      8  I-NAME_STUDENT\n20      20        56      8  B-NAME_STUDENT\n21      21        56      9  I-NAME_STUDENT\n22      22        86      7  B-NAME_STUDENT\n23      23        86      8  B-NAME_STUDENT\n24      24        86      9  I-NAME_STUDENT\n25      25        93      1  B-NAME_STUDENT\n26      26        93      2  I-NAME_STUDENT\n27      27        93      3  I-NAME_STUDENT\n28      28        93      4  I-NAME_STUDENT\n29      29       104      7  B-NAME_STUDENT\n30      30       104      8  I-NAME_STUDENT\n31      31       104      9  I-NAME_STUDENT\n32      32       112      5  B-NAME_STUDENT\n33      33       112      6  I-NAME_STUDENT\n34      34       123     28  B-NAME_STUDENT\n35      35       123     29  I-NAME_STUDENT","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>document</th>\n      <th>token</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7</td>\n      <td>11</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>7</td>\n      <td>12</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>7</td>\n      <td>13</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>460</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>7</td>\n      <td>461</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>7</td>\n      <td>462</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>7</td>\n      <td>706</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>7</td>\n      <td>707</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>7</td>\n      <td>708</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>10</td>\n      <td>1</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>10</td>\n      <td>2</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>10</td>\n      <td>433</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>10</td>\n      <td>434</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>16</td>\n      <td>4</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>16</td>\n      <td>5</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>16</td>\n      <td>6</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>20</td>\n      <td>5</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>20</td>\n      <td>6</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>20</td>\n      <td>7</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>20</td>\n      <td>8</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>56</td>\n      <td>8</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>56</td>\n      <td>9</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>86</td>\n      <td>7</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>86</td>\n      <td>8</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>86</td>\n      <td>9</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>93</td>\n      <td>1</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>93</td>\n      <td>2</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>93</td>\n      <td>3</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>93</td>\n      <td>4</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>104</td>\n      <td>7</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>30</td>\n      <td>104</td>\n      <td>8</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>31</td>\n      <td>104</td>\n      <td>9</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32</td>\n      <td>112</td>\n      <td>5</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>33</td>\n      <td>112</td>\n      <td>6</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>34</td>\n      <td>123</td>\n      <td>28</td>\n      <td>B-NAME_STUDENT</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>35</td>\n      <td>123</td>\n      <td>29</td>\n      <td>I-NAME_STUDENT</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Conclusion\n\n<font size=\"4\"> We were able to use the Hugging Face Deberta v3 Base model for this task. Some notable observations that I found during this experiment were the following:\n\n**<font size=\"4\">1. The importance of handling extreme imbalance in datasets:** <font size=\"4\">Various techniques were attempted to address the extreme data imbalance. Undersampling the majority class does not leave enough data to properly train the model, while oversampling creates a data set too large to train in a reasonable time. Additional research could be completed to find time-efficient techniques for handling extreme data imbalance.\n\n**<font size=\"4\">2. Importance of verifying correct tokenization:** <font size=\"4\">I found that tokenizing and aligning the data was the most challenging part of this experiment. It is important to choose a tokenizer that best works for a given task. It is also important to visually and programmatically check that the tokenizer has worked correctly.\n\n**<font size=\"4\">3. Robust options available for PII detection:** <font size=\"4\">Hugging Face provides hundreds of free-to-use models for experimentation. Also, other packages such as Spacy and Microsoft Presidio offer lightweight solutions for similar tasks with smaller data sets. It is important to choose an appropriate model for the given structure of the data set, data set size, etc.\n\n<font size=\"4\">I am appreciative of other Kaggle users who have submitted and made their notebooks public for this competition. Participating in this competition has allowed me to learn about various techniques and packages for PII detection. Thank you to the Kaggle platform and the host of this competition. Please feel free to leave comments, feedback, suggestions, etc. Feedback from the Kaggle and data science community would be greatly appreciated.\n","metadata":{}},{"cell_type":"code","source":"# Capture the end time\nend_time = time.time()\nprint(\"End Time: \", time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time)))\n\n# Calculate the duration\nduration = end_time - start_time\n\n# Convert duration to minutes and seconds\nminutes = int(duration // 60)\nseconds = int(duration % 60)\n\nprint(f\"Notebook Run Time Duration: {minutes} minutes and {seconds} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-08-08T01:33:50.823655Z","iopub.execute_input":"2024-08-08T01:33:50.823948Z","iopub.status.idle":"2024-08-08T01:33:50.834222Z","shell.execute_reply.started":"2024-08-08T01:33:50.823923Z","shell.execute_reply":"2024-08-08T01:33:50.833375Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"End Time:  2024-08-08 01:33:50\nNotebook Run Time Duration: 113 minutes and 2 seconds\n","output_type":"stream"}]}]}